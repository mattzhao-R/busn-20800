{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', color_codes=True, rc={'figure.figsize':(11,8)}, font_scale=2)\n",
    "\n",
    "from sklearn.linear_model import Lasso, LassoCV, LassoLarsIC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DATA_DIR = '/classes/2080001_spr2022/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('%s/loan_train_07_18.csv'%(_DATA_DIR), index_col =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing, change string type x % to x.\n",
    "df.revol_util = df.revol_util.apply(lambda x: str(x)[:-1])\n",
    "df.revol_util = df.revol_util.replace('na','0')\n",
    "df.revol_util = df.revol_util.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x=\"loan_status\", y=\"mort_acc\", data=df)\n",
    "\n",
    "plt.title('number of mortgage accounts')\n",
    "plt.xlabel('Default category')\n",
    "plt.ylabel('number of mortgage accounts')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x=\"loan_status\", y=\"dti\", data=df)\n",
    "\n",
    "plt.title('borrower’s debt-to-income ratio')\n",
    "plt.xlabel('Default category')\n",
    "plt.ylabel('borrower’s debt-to-income ratio')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x=\"loan_status\", y=\"annual_inc\", data=df)\n",
    "\n",
    "plt.title('annual income')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xlabel('Default category')\n",
    "plt.ylabel('annual income')\n",
    "plt.yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablegrade = pd.crosstab(df['grade'], df.loan_status)\n",
    "tablegrade.div(tablegrade.sum(1).astype(float), axis=0).plot(kind='bar', stacked = True,figsize = (10,6))\n",
    "plt.title('Stacked Bar Chart of grade')\n",
    "plt.xlabel('Loan grade')\n",
    "plt.ylabel('Proportion of Applicants')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablesub = pd.crosstab(df['sub_grade'], df.loan_status)\n",
    "tablesub.div(tablesub.sum(1).astype(float), axis=0).plot(kind='bar', stacked = True,figsize = (20,6))\n",
    "plt.title('Stacked Bar Chart of sub grade')\n",
    "plt.xlabel('Loan sub-grade')\n",
    "plt.ylabel('Proportion of Applicants')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablehome = pd.crosstab(df['home_ownership'], df.loan_status)\n",
    "tablehome.div(tablehome.sum(1).astype(float), axis=0).plot(kind='bar', stacked = True,figsize = (10,6))\n",
    "plt.title('Stacked Bar Chart of home ownership')\n",
    "plt.xlabel('home ownership')\n",
    "plt.ylabel('Proportion of Applicants')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.loc[:,['int_rate','sub_grade','grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.sort_values('grade')\n",
    "plt.figure(figsize = (16,12))\n",
    "sns.boxplot(data = temp, x = 'grade', y = 'int_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.sort_values('sub_grade')\n",
    "plt.figure(figsize = (20,12))\n",
    "sns.boxplot(data = temp, x = 'sub_grade', y = 'int_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change predicted value into binary numerical value 0,1\n",
    "status_values = {'Fully Paid': 0, 'Charged Off': 1}\n",
    "df['loan_status'] = df.loan_status.map(status_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('id',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = pd.DataFrame(df.corr()['loan_status'].drop('loan_status').sort_values())\n",
    "cor['variable'] = cor.index\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "sns.barplot(\n",
    "    x=\"loan_status\", \n",
    "    y=\"variable\", \n",
    "    data=cor, \n",
    "    estimator=sum\n",
    ");\n",
    "plt.title('correlation with loan status')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/classes/2080001_spr2022/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train = pd.read_csv('%s/loan_train_07_18.csv'%(_DATA_DIR), index_col =0)\n",
    "\n",
    "# Data preprocessing, change string type x % to x.\n",
    "\n",
    "loan_train.revol_util = loan_train.revol_util.apply(lambda x: str(x)[:-1])\n",
    "loan_train.revol_util = loan_train.revol_util.replace('na','0')\n",
    "loan_train.revol_util = loan_train.revol_util.astype(np.float64)\n",
    "\n",
    "# Change predicted value into binary numerical value 0,1\n",
    "status_values = {'Fully Paid': 0, 'Charged Off': 1}\n",
    "loan_train['loan_status'] = loan_train.loan_status.map(status_values)\n",
    "\n",
    "\n",
    "from Data_cleaning import Data_cleaning, Data_cleaning_grade\n",
    "loan_train_cleaned = Data_cleaning(loan_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean test dataset\n",
    "loan_test = pd.read_csv('%s/loan_test_19_20.csv'%(_DATA_DIR), index_col =0)\n",
    "\n",
    "loan_test.int_rate = loan_test.int_rate.apply(lambda x: float(x[:-1]))\n",
    "loan_test.revol_util = loan_test.revol_util.apply(lambda x: str(x)[:-1])\n",
    "loan_test.revol_util = loan_test.revol_util.replace('na','0')\n",
    "loan_test.revol_util = loan_test.revol_util.astype(np.float64)\n",
    "\n",
    "\n",
    "from Data_cleaning import Data_cleaning, Data_cleaning_grade\n",
    "loan_test_cleaned = Data_cleaning(loan_test)\n",
    "\n",
    "status_values = {'Fully Paid': 0, 'Charged Off': 1}\n",
    "loan_test_cleaned ['loan_status'] = loan_test_cleaned .loan_status.map(status_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train_cleaned.loan_status.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_test_cleaned.loan_status.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_col = np.unique(loan_train[['grade']])\n",
    "subgrade_col = np.unique(loan_train[['sub_grade']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def Model_construction(X_train,y_train,method,penalty):\n",
    "    \n",
    "    Xscaler = StandardScaler().fit(X_train) \n",
    "    X_train = Xscaler.transform(X_train)    \n",
    "    \n",
    "    if method == 'Imbalanced':\n",
    "        if  penalty == 'l1':\n",
    "            lr_model = LogisticRegression(class_weight='balanced',penalty = 'l1',solver ='saga').fit(X_train,y_train)\n",
    "        if penalty == 'none':  \n",
    "            lr_model = LogisticRegression(class_weight='balanced').fit(X_train,y_train)\n",
    "    \n",
    "    if method == 'Null':\n",
    "        if penalty == 'l1':\n",
    "            lr_model = LogisticRegression(penalty = 'l1',solver ='saga').fit(X_train,y_train)\n",
    "        if penalty == 'none':\n",
    "            lr_model = LogisticRegression().fit(X_train,y_train)\n",
    "    \n",
    "    return lr_model, Xscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = loan_train_cleaned.drop(columns = ['int_rate','loan_status','grade','sub_grade','id'])\n",
    "y_train = loan_train_cleaned.loan_status\n",
    "\n",
    "X_test = loan_test_cleaned.drop(columns = ['int_rate','loan_status','grade','sub_grade','id'])\n",
    "y_test = loan_test_cleaned.loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Xscaler = StandardScaler().fit(X_train) \n",
    "X_train = Xscaler.transform(X_train)  \n",
    "\n",
    "lr_model = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "X_test =  Xscaler.transform(X_test)  \n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.DataFrame({'Grade': loan_test_cleaned.grade,'Sub_Grade':loan_test_cleaned.sub_grade,'True':y_test,'Predict':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.groupby('Grade').sum().plot(kind ='bar', figsize = (8,6))\n",
    "plt.title('Logistic Regression (grade)')\n",
    "plt.savefig('lg_grade.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.groupby('Sub_Grade').sum().plot(kind ='bar', figsize = (20,6))\n",
    "plt.title('Logistic Regression (subgrade)')\n",
    "plt.savefig('lg_subgrade.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "lr_model = LogisticRegression(penalty = 'l1',solver = 'saga',C=100).fit(X_train,y_train)\n",
    "\n",
    "X_test =  Xscaler.transform(X_test)  \n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "df_summary_lasso = pd.DataFrame({'Grade': loan_test_cleaned.grade,'Sub_Grade':loan_test_cleaned.sub_grade,'True':y_test,'Predict':y_pred})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_lasso.groupby('Grade').sum().plot(kind ='bar', figsize = (8,6))\n",
    "plt.title('Logistic Regression, Lasso(grade)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_lasso.groupby('Grade').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_lasso.groupby('Sub_Grade').sum().plot(kind ='bar', figsize = (20,6))\n",
    "plt.title('Logistic Regression, Lasso (subgrade)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two variable logistic regression\n",
    "X_train_2 = loan_train_cleaned[['mort_acc','dti']]\n",
    "\n",
    "X_test_2 = loan_test_cleaned[['mort_acc','dti']]\n",
    "\n",
    "\n",
    "lr_model = LogisticRegression().fit(X_train_2,y_train)\n",
    "\n",
    "\n",
    "y_pred = lr_model.predict(X_test_2)\n",
    "    \n",
    "\n",
    "df_summary_2 = pd.DataFrame({'Grade': loan_test_cleaned.grade,'Sub_Grade':loan_test_cleaned.sub_grade,'True':y_test,'Predict':y_pred})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_2.groupby('Grade').sum().plot(kind ='bar', figsize = (8,6))\n",
    "plt.title('Logistic Regression, 2 variables (grade)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_2.groupby('Sub_Grade').sum().plot(kind ='bar', figsize = (20,6))\n",
    "plt.title('Logistic Regression, 2 variables (subgrade)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train = loan_train_cleaned[['id','loan_status','mort_acc','dti','grade','sub_grade']]\n",
    "\n",
    "knn_test = loan_test_cleaned [['id','loan_status','mort_acc','dti','grade','sub_grade']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "\n",
    "# X = df_knn.drop(columns = 'loan_status')\n",
    "X_train = knn_train[['mort_acc','dti']]\n",
    "y_train = knn_train[['loan_status']]\n",
    "\n",
    "Xscaler = StandardScaler().fit(X_train) \n",
    "X_train = Xscaler.transform(X_train)\n",
    "\n",
    "\n",
    "X_test = knn_test[['mort_acc','dti']]\n",
    "y_test = knn_test[['loan_status']]\n",
    "\n",
    "\n",
    "X_test = Xscaler.transform(X_test)\n",
    "\n",
    "nn1 = KNeighborsClassifier(n_neighbors=1,n_jobs=-1).fit(X_train, y_train)\n",
    "nn5 = KNeighborsClassifier(n_neighbors=5,n_jobs=-1).fit(X_train, y_train)\n",
    "nn20 = KNeighborsClassifier(n_neighbors=20,n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = nn1.predict(X_test) \n",
    "y_pred_5 = nn5.predict(X_test) \n",
    "y_pred_20 = nn20.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_result = pd.DataFrame(columns = ['Grade','Sub_Grade','True','1-nn','5-nn','20-nn'])\n",
    "\n",
    "knn_result.loc[:,'Grade'] = knn_test.loc[:,'grade']\n",
    "knn_result.loc[:,'Sub_Grade'] = knn_test.loc[:,'sub_grade']\n",
    "knn_result.loc[:,'True'] = y_test.loan_status\n",
    "knn_result.loc[:,'1-nn'] = y_pred_1 \n",
    "knn_result.loc[:,'5-nn'] = y_pred_5\n",
    "knn_result.loc[:,'20-nn'] = y_pred_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_result.groupby('Grade').sum().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_result.groupby('Sub_Grade').sum().plot(kind = 'bar', figsize = (28,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the confusion matrix\n",
    "CM_1 = confusion_matrix(y_test.loan_status,knn_result['1-nn'])\n",
    "CM_5 =  confusion_matrix(y_test.loan_status,knn_result['5-nn'])\n",
    "CM_20 =  confusion_matrix(y_test.loan_status,knn_result['20-nn'])\n",
    "\n",
    "# Calculate Accuracy\n",
    "Acc_1 = (CM_1[0,0] + CM_1[1,1])/CM_1.sum()\n",
    "Acc_5 = (CM_5[0,0] + CM_5[1,1])/CM_5.sum()\n",
    "Acc_20 = (CM_20[0,0] + CM_20[1,1])/CM_20.sum()\n",
    "\n",
    "# Calculate FPR & FNR\n",
    "\n",
    "FPR_1 = CM_1[0,1] / (CM_1[0,1]+CM_1[0,0])\n",
    "FPR_5 = CM_5[0,1] / (CM_5[0,1]+CM_5[0,0])\n",
    "FPR_20 = CM_20[0,1] / (CM_20[0,1]+CM_20[0,0])\n",
    "\n",
    "\n",
    "FNR_1 = CM_1[1,0] / (CM_1[1,0]+CM_1[1,1])\n",
    "FNR_5 = CM_5[1,0] / (CM_5[1,0]+CM_5[1,1])\n",
    "FNR_20 = CM_20[1,0] / (CM_20[1,0]+CM_20[1,1])\n",
    "\n",
    "\n",
    "print('---Calculate Accuracy---')\n",
    "print('1-NN:', Acc_1)\n",
    "print('5-NN:', Acc_5)\n",
    "print('20-NN:', Acc_20)\n",
    "print('------------------------')\n",
    "print('-----Calculate FPR------')\n",
    "print('1-NN:', FPR_1)\n",
    "print('5-NN:', FPR_5)\n",
    "print('20-NN:', FPR_20)\n",
    "print('------------------------')\n",
    "print('-----Calculate FNR------')\n",
    "print('1-NN:', FNR_1)\n",
    "print('5-NN:', FNR_5)\n",
    "print('20-NN:', FNR_20)\n",
    "print('------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression result\n",
    "\n",
    "lg_null = confusion_matrix(y_test.loan_status,df_summary.Predict)\n",
    "lg_2 =  confusion_matrix(y_test.loan_status,df_summary_2.Predict)\n",
    "lg_lasso =  confusion_matrix(y_test.loan_status,df_summary_lasso.Predict)\n",
    "\n",
    "# Calculate Accuracy\n",
    "Acc_lg_null = (lg_null[0,0] + lg_null[1,1])/lg_null.sum()\n",
    "Acc_lg_2 = (lg_2[0,0] + lg_2[1,1])/lg_2.sum()\n",
    "Acc_lg_lasso = (lg_lasso[0,0] + lg_lasso[1,1])/lg_lasso.sum()\n",
    "\n",
    "# Calculate FPR & FNR\n",
    "\n",
    "FPR_null = lg_null[0,1] / (lg_null[0,1]+lg_null[0,0])\n",
    "FPR_2 = lg_2[0,1] / (lg_2[0,1]+lg_2[0,0])\n",
    "FPR_lasso = lg_lasso[0,1] / (lg_lasso[0,1]+lg_lasso[0,0])\n",
    "\n",
    "\n",
    "FNR_null = lg_null[1,0] / (lg_null[1,0]+lg_null[1,1])\n",
    "FNR_2 = CM_5[1,0] / (lg_2[1,0]+lg_2[1,1])\n",
    "FNR_lasso = lg_lasso[1,0] / (lg_lasso[1,0]+lg_lasso[1,1])\n",
    "\n",
    "print('---Calculate Accuracy---')\n",
    "print('Logistic regression (plain):',Acc_lg_null)\n",
    "print('Logistic regression 2 variables:', Acc_lg_2)\n",
    "print('Logistic regression lasso:', Acc_lg_lasso)\n",
    "print('------------------------')\n",
    "print('-----Calculate FPR------')\n",
    "print('Logistic regression (plain):',FPR_null)\n",
    "print('Logistic regression 2 variables:', FPR_2)\n",
    "print('Logistic regression lasso:', FPR_lasso)\n",
    "print('------------------------')\n",
    "print('-----Calculate FNR------')\n",
    "print('Logistic regression (plain):',FNR_null)\n",
    "print('Logistic regression 2 variables:', FNR_2)\n",
    "print('Logistic regression lasso:', FNR_lasso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC & AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "Xscaler = StandardScaler().fit(X_train) \n",
    "X_train = Xscaler.transform(X_train)  \n",
    "\n",
    "lr_model = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "X_test =  Xscaler.transform(X_test)  \n",
    "\n",
    "y_pred_pro = lr_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_pro)\n",
    "\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logit (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r',linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC (Logit)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('ROC.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with Lasso\n",
    "lr_model = LogisticRegression(penalty = 'l1',solver = 'saga').fit(X_train,y_train)\n",
    "\n",
    "X_test =  Xscaler.transform(X_test)  \n",
    "\n",
    "y_pred_pro_lasso = lr_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_pro_lasso)\n",
    "\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logit Lasso (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r',linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC (Logit Lasso)')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.savefig('ROC.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two variable logistic regression\n",
    "lr_model = LogisticRegression().fit(X_train_2,y_train)\n",
    "\n",
    "\n",
    "y_pred_prob_2 = lr_model.predict_proba(X_test_2)[:,1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_2)\n",
    "\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logit 2 (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r',linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC (Logit 2)')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.savefig('ROC.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from data_utils import load_CIFAR10\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "Xtr, Ytr, Xte, Yte = load_CIFAR10(_DATA_DIR+'/cifar-10-data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "classes = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 10\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(Ytr== y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(Xtr[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data example\n",
    "# It's a frog\n",
    "plt.imshow(Xtr[0]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[Ytr[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten out all images to be one-dimensional\n",
    "Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072\n",
    "Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "MLR = LogisticRegression(multi_class='multinomial', solver='saga',random_state=0)\n",
    "MLR.fit(Xtr_rows[:5000], Ytr[:5000])\n",
    "\n",
    "y_pred_MLR = MLR.predict(Xte_rows[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(Xte[i]/255)\n",
    "    plt.title(classes[Yte[i]]+'('+classes[y_pred_MLR[i]]+')')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_result = pd.DataFrame({'True':Yte[:1000],'Predict':y_pred_MLR})\n",
    "CIFAR10_result['Correct'] = CIFAR10_result.iloc[:,0] - CIFAR10_result.iloc[:,1]\n",
    "Acc_cifar = (CIFAR10_result['Correct'] == 0).sum()/CIFAR10_result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc_cifar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 error\n",
    "y_pred_prob = MLR.predict_proba(Xte_rows[:1000])\n",
    "\n",
    "predict_prob = pd.DataFrame(y_pred_prob)\n",
    "predict_prob.columns = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_5 = pd.DataFrame(np.argsort(y_pred_prob)[:,-5:])\n",
    "Top_5['True'] = Yte[:1000]\n",
    "Top_5['Correct'] = (Top_5['True'] - Top_5[4]) * (Top_5['True'] - Top_5[3]) * (Top_5['True'] - Top_5[2]) * (Top_5['True'] - Top_5[1]) * (Top_5['True']-Top_5[0])\n",
    "(Top_5['Correct'] == 0).sum()/Top_5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
