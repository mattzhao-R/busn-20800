{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Model selection and regularization\n",
    "## BUS 20800: Big Data\n",
    "## Due: 11:59 am on Apr 22, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. **In-Sample and Out-of-Sample Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Linear model**\n",
    "\n",
    "Consider a linear regression model with $p$ parameters, fit by least squares to a set of training data $(x_1, y_1), . . . , (x_N, y_N)$ drawn at random from a population. Let $\\hat{\\beta}$ be the least squares estimate. Suppose we have\n",
    "some test data $(\\tilde{x}_1, \\tilde{y}_1), . . . , (\\tilde{x}_M, \\tilde{y}_M)$ drawn at random from the same population as the training data. Set\n",
    "\n",
    "$$L_{train}\\ \\ (\\beta) = \\frac{1}{N}\\sum_{i=1}^N(y_i - \\beta^TX_i)^2\n",
    "$$\n",
    "$$\n",
    "L_{test}\\ \\ (\\beta) = \\frac{1}{M}\\sum_{i = 1}^M(\\tilde{y}_i-\\beta^T\\tilde{X}_i)^2\n",
    "$$\n",
    "\n",
    "Show that\n",
    "$$\n",
    "\\mathbb{E}(L_{train}\\ \\ (\\hat{\\beta})) \\leq \\mathbb{E}(L_{test}\\ \\ (\\hat{\\beta}))\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. **Ridge Regression and Correlation Screening**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Ridge and OLS**\n",
    "\n",
    "Show that the ridge regression estimates can be obtained by OLS on an augmented data set. We augment the centered matrix $X$ with $p$ additional rows $\\sqrt{\\lambda}I$, and augment $y$ with $p$ zeros. By introducing artificial data with response value being zero, the fitting procedure is forced to shrink the coefficients toward zero. \n",
    "\n",
    "**Answer** :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2. Analytical formula for Ridge**\n",
    "\n",
    "Show that for the ridge problem\n",
    "\n",
    "$$\\hat{\\beta}_{ridge} = argmin _{\\beta}||Y-X\\beta||^2_2 +\\lambda ||\\beta||_2^2\n",
    "$$\n",
    "\n",
    "has the closed form:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{ridge} = (X^TX+\\lambda I_d)^{-1}X^TY\n",
    "$$\n",
    "\n",
    "where $I_d$ is the identity matrix.\n",
    "\n",
    "\n",
    "**Answer**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Ridge and Correlation Screening**\n",
    "\n",
    "Consider a linear regression model $Y=X\\beta+\\varepsilon$, where $y$ is the $n × 1$ response vector, $X$ is the $n × p$ design matrix, $\\beta$ is the $p × 1$ regression coefficient vector, and $\\varepsilon$ is the $n×1$ random error vector with $E(\\varepsilon) = 0$ and $Cov(ε) = \\sigma^2 I_{d}$.\n",
    "\n",
    "Assume each column of $X$ has zero mean and unit variance.\n",
    "\n",
    "Use results of 2.2 to show that when $\\lambda → \\infty$, ridge regression outputs are exactly the correlations used in screening.\n",
    "\n",
    "\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup codes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style='white')\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3. **Best Subset, Forward Stepwise and Backward Stepwise Regression**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we simluate a linear regression problem, and compare selected features based on different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Data Generating Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a linear regression problem $y = X^T\\beta +\\varepsilon$.  Suppose there are 300 observations on 16 standard Gaussian variables, with pairwise correlations all equal to 0.85. For the first 6 variables, the coefficients are drawn from a $N(0,0.4)$ distribution; the rests are 0. Therefore, the true DGP of $y$ only depends on the first 6 entires of $X$ variables. The noise follows $N(0,6.25)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP, you don't need to modify any codes here.\n",
    "N = 300\n",
    "p = 16\n",
    "rou = 0.85\n",
    "num_signals = 6\n",
    "sigma = np.ones((p,p)) * rou + (1-rou) * np.identity(p)\n",
    "X = np.random.multivariate_normal(np.repeat(0,p), sigma, size = N)\n",
    "X = pd.DataFrame(data = X)\n",
    "beta = np.random.normal(0,0.4,num_signals).tolist()+ np.repeat(0,p-num_signals).tolist()\n",
    "noise = np.random.normal(0,6.25, N)\n",
    "\n",
    "y = X.dot(beta) +noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Compare Three Methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now we want to decide the best regression model with $k$ regressors, for each given $k$, where $k = 1,2,\\cdots, p$, respectively. \n",
    "\n",
    "For best subset selection regression, how many models do you compare? What about forward stepwise and backward stepwise regressions?\n",
    "\n",
    "\n",
    "**Answer**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see which model is selected by these three methods for a given $k$ number of regressors, and compare their running time.\n",
    "\n",
    "Please finish Best_subset_selection, Forward_stepwise_selection, Backward_stepwise_selection in Stepwise_simulation.py before you run the following cells. You don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Stepwise_simulation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 3 methods will output the variables it selected with different numbers of regessors, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Subset selection\n",
    "# Please finish the codes in Best_subset_selection(X,y,p)\n",
    "df_best,time_best = Best_subset_selection(X,y,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Stepwise selection\n",
    "# Please finish the codes in Forward_stepwise_selection(X,y,p)\n",
    "df_forward, time_forward = Forward_stepwise_selection(X,y,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Stepwise selection\n",
    "# Please finish the codes in Backward_stepwise_selection(X,y,p)\n",
    "df_backward, time_backward = Backward_stepwise_selection(X,y,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to visualize the running time. You don't need to modify any codes here.\n",
    "\n",
    "running_time = pd.DataFrame({'Best Subset': np.log(time_best),'Forward Stepwise': np.log(time_forward),'Backward Stepwise': np.log(time_backward)})\n",
    "running_time.index = range(1,16)\n",
    "\n",
    "# Visualize the results\n",
    "running_time.plot(figsize = (10,6))\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Log running time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this plot and these output DataFrames, comment on what you find. \n",
    "\n",
    "\n",
    "**Answer**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4. Sparse Signal Recovery\n",
    "\n",
    "In this exercise, we will generate a simulated linear regression problem and use Lasso to see if this method can recover the sparse signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Data Generating Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP, you don't need to modify any codes here\n",
    "\n",
    "n_samples, n_features = 50, 100\n",
    "num_signal = 10\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Construct the signals\n",
    "idx = np.arange(n_features)\n",
    "\n",
    "coef = 5 * np.random.randn(n_features)\n",
    "inds = np.arange(n_features)\n",
    "\n",
    "# Shuffle index and sparsify the signals\n",
    "np.random.shuffle(inds)\n",
    "coef[inds[num_signal:]] = 0\n",
    "\n",
    "# Add noise\n",
    "y = np.dot(X, coef) + 0.01 * np.random.normal(size=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Fit Lasso for signal recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in training set and test set. You don't need to modify any codes here.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please finish the following cell to fit Lasso, output a model named lasso, and calculate the OOS R^2: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "##############################################################################\n",
    "### TODO: Fit a lasso model here, and calculate the OOS R square           ###\n",
    "##############################################################################\n",
    "\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize and compare the results. You don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(lasso.coef_, color='gold', linewidth=2, label='Lasso coefficients')\n",
    "plt.plot(coef, '--', color='navy', label='original coefficients')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5. **Track S&P500 index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Background**: \n",
    "\n",
    "The S&P 500 Index, or Standard & Poor's 500 Index, is a market-capitalization-weighted index of 500 (approximately) leading publicly traded companies in the U.S. It is regarded as one of the best gauges of prominent American equities' performance, and by extension, that of the stock market overall.\n",
    "\n",
    "In this exercise, we consider the daily values of the SP500 index as well as the daily stock prices of 500 major stocks at the same time period.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Purpose**:\n",
    "\n",
    "You can't directly invest in the S&P 500 because it's an index. Buying a basket of all component stocks may induce high transaction costs. Instead, one may be interested in a portfolio which contains fewer stocks to track the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "sp500 = pd.read_csv('index_track.csv', index_col = 0)\n",
    "sp500 = sp500.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up codes\n",
    "from Index_track import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.  Construct a parsimonious portfolio \n",
    "\n",
    "Construct a parsimonious portfolio that tracks  the S\\&P500\n",
    "index approximately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the next cell to construct a Portfolio using training set and use Portfolio_visualize to check the OOS performance of this portfolio. \n",
    "\n",
    "Note we do not shuffle data when creating training set and test set on time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on price information to get stock returns for the index and individual stocks\n",
    "\n",
    "sp500_ret = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Portfolio_construction()\n",
    "\n",
    "Portfolio_visualize(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many stocks have non-zero weights?\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different tuning parameters to see how this changes the above question. \n",
    "\n",
    "What results do you find when tuning parameter = 0 / $\\infty$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Rebalance the portfolio\n",
    "\n",
    "In this exercise, we implement the above portfolio on a rolling window basis. Say, use the first 60-day window to train your model, and use the next 60 day as OOS to check its performance, and continue for the rest of the OOS periods. \n",
    "\n",
    "\n",
    "Finish the codes in Portfolio_rebalance() and run the cell below to construct and evalute this portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio_rebalance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio_visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many stocks have the non-zero weight? How stable is your portfolio? \n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
