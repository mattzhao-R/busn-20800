{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1136b17c",
   "metadata": {},
   "source": [
    "# Assignment 6: Trees\n",
    "\n",
    "## BUS 20800: Big Data\n",
    "## Due: 11:59 am on May 13, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ad8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up codes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', color_codes=True, font_scale=1.5)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e0568",
   "metadata": {},
   "source": [
    "# Problem 1. Tree method in Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120791c",
   "metadata": {},
   "source": [
    "In this exercise, we will revisit the moon shape, circle shape, and the balanced linearly separable data in Assignment 2. Now use CART and Random Forest to redo the classification task and visualize the decision boundary. Compare the results with K-nn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7599c8b",
   "metadata": {},
   "source": [
    "## Part I. Data Generating Processs (DGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6260eed",
   "metadata": {},
   "source": [
    "Run the following codes to get the moon shape, circle shape, and balanced linearly separable data. They are stored in a dictionary structure named 'datasets'.\n",
    "\n",
    "You don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e004b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles,make_blobs\n",
    "\n",
    "\n",
    "h = 0.02  # step size in the mesh\n",
    "\n",
    "n_samples = 1500\n",
    "\n",
    "datasets = [\n",
    "    make_moons(n_samples=n_samples,noise=0.05, random_state=0),\n",
    "    make_circles(n_samples=n_samples,noise=0.05, factor=0.5, random_state=1),\n",
    "    make_blobs(n_samples=n_samples, random_state=8,centers=2,center_box = (-4,4))\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc597f0",
   "metadata": {},
   "source": [
    "## Part II. Initialize the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa81871",
   "metadata": {},
   "source": [
    "Run the following codes to initialize the K-nn, CART, and Random Forest classifier. Store them in a dictionary structure named 'classifiers'.\n",
    "\n",
    "You don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "names = [\"Nearest Neighbors\",\"Decision Tree\",\"Random Forest\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd94e71",
   "metadata": {},
   "source": [
    "## Part III. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd3eaa",
   "metadata": {},
   "source": [
    "Finish the codes in the iteration and run the below cells to visualize the decision boundary.\n",
    "\n",
    "\n",
    "(1) Split the data into training and test set.\n",
    "(With variable name 'X_train', 'X_test', 'y_train', 'y_test', respectively.)\n",
    "\n",
    "(2) Train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59baa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "figure = plt.figure(figsize=(27, 20))\n",
    "i = 1\n",
    "\n",
    "# Iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    \n",
    "    X, y = ds # X is the feature and y is the label\n",
    "    \n",
    "##############################################################################\n",
    "### TODO:  Preprocess dataset(named ds), split into training and test part ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Visualize the original dataset\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\", size = 35)\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    \n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\")\n",
    "    \n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    # Iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        \n",
    "##############################################################################\n",
    "### TODO: Train different classifiers and get OOS accuracy                 ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################\n",
    "\n",
    "        # Plot the decision boundary. \n",
    "        \n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else: # Z variable captures the probability which we use for coloring the decision boundaries\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=0.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0],X_test[:, 1],c=y_test,cmap=cm_bright,edgecolors=\"k\",alpha=0.6,)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name, size = 35)\n",
    "        ax.text(\n",
    "            xx.max() - 0.3,\n",
    "            yy.min() + 0.3,\n",
    "            (\"%.2f\" % score).lstrip(\"0\"),\n",
    "            size=35,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219cbf4",
   "metadata": {},
   "source": [
    "## Part IV. Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d64cea",
   "metadata": {},
   "source": [
    "Based on the decision boundary you have generated in the above exercise, what conclusion can you make? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39291680",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0a161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eda4ad9",
   "metadata": {},
   "source": [
    "# Problem 2. Tree method in Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35c8bd",
   "metadata": {},
   "source": [
    "In this exercise, you need to use a regression tree to solve a 1D regression problem with some simulated data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf324fb",
   "metadata": {},
   "source": [
    "## Part I. Data Generating Process (DGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d44da5",
   "metadata": {},
   "source": [
    "Run the following codes to generate a sine shape curve with noise. We have separated the training data and test data for you.\n",
    "\n",
    "You don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP\n",
    "rng = np.random.RandomState(1)\n",
    "X_train = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "y_train = np.sin(X_train).ravel()\n",
    "y_train[::5] += 3 * (0.5 - rng.rand(16))\n",
    "\n",
    "rng = np.random.RandomState(10)\n",
    "X_test = np.sort(5 * rng.rand(40, 1), axis=0)\n",
    "y_test = np.sin(X_test).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c48849",
   "metadata": {},
   "source": [
    "## Part II. Build a regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77b747",
   "metadata": {},
   "source": [
    "Utilize the Regression Tree to fit the training set and evaluate it on the test set with the metrics MSE and R squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "##############################################################################\n",
    "### TODO: Build a regression tree and evaluate its OOS performance.        ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "# Get prediciton In Sample and OOS\n",
    "y_pred_IS = \n",
    "y_pred_OOS =\n",
    "\n",
    "# OOS evaluation\n",
    "MSE = \n",
    "r2 = \n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error: %f\" %(MSE))\n",
    "print(\"R2 Score: %f\" %(r2))\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943a339",
   "metadata": {},
   "source": [
    "Run the following codes to visualize the In-Sample and OOS prediction results.\n",
    "\n",
    "You don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Sample Visualization\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "ax = plt.gca()\n",
    "ax.plot(X_train, y_train,label = 'True value')\n",
    "ax.plot(X_train,y_pred_IS,label = 'Regression Tree')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b2ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOS Visualization\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "ax = plt.gca()\n",
    "ax.plot(X_test, y_test,label = 'True value')\n",
    "ax.plot(X_test,y_pred_OOS,label = 'Regression Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02588e7c",
   "metadata": {},
   "source": [
    "Based on the above two graphs, what conclusion can you make? Will tree overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016a6f5",
   "metadata": {},
   "source": [
    "## Part III. Trees with different depths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8974f9",
   "metadata": {},
   "source": [
    "Now redo the exercise in Part II and build regression trees with different max depths. \n",
    "Visualize the In-Sample and OOS on the same graph. What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Build regression tress with different depth.                     ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2497b7a",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd46ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc9005cb",
   "metadata": {},
   "source": [
    "# Problem 3. Random Forest and Variable Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a313e22",
   "metadata": {},
   "source": [
    "In this exercise, you need to build a random forest to select the most important variables on a simulated classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e804119",
   "metadata": {},
   "source": [
    "## Part I. Data Generating Process (DGP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f32cc",
   "metadata": {},
   "source": [
    "Run the following cell to generate the simulated binary-class classification data. \n",
    "\n",
    "In this artificial classification data, we have:\n",
    "\n",
    "+ #n_informative features that are important\n",
    "+ #n_redundant features that are linear combinations of the informative features.\n",
    "+ #n_repeated features that are duplicated features, they are drawn randomly from the informative and the redundant features\n",
    "\n",
    "\n",
    "We have separate the training set and test set for you.\n",
    "\n",
    "\n",
    "You don't need to modify any codes here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=3,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    random_state=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a0552",
   "metadata": {},
   "source": [
    "## Part II. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cb643",
   "metadata": {},
   "source": [
    "Build a random forest and get the variable importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae043a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Build a random forest and get the variable importance.           ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c774e16",
   "metadata": {},
   "source": [
    "## Part III. Experiments and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c3aa8",
   "metadata": {},
   "source": [
    "Try to set n_informative, n_redundant and n_repeated to different numbers and redo the exercise, what results do you find?\n",
    "\n",
    "Explain intuitively why Random Forest can be used as a method for feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf083d7",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4edcddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96658cdf",
   "metadata": {},
   "source": [
    "# Problem 4. Breast cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5a5c6",
   "metadata": {},
   "source": [
    "In this exercise, you will build a tree based classifier and do some variable selections to prdict the OOS label. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387eab2",
   "metadata": {},
   "source": [
    "Run the following codes to get the breast cancer dataset. We have splited the training set and test set for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X = pd.DataFrame(X, columns = data.feature_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85693e",
   "metadata": {},
   "source": [
    "## Part I. Logistic regreesion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabdf09",
   "metadata": {},
   "source": [
    "Use logistic regression to do the classification task and report the OOS accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "##############################################################################\n",
    "### TODO: Use logistic regression to do the classification task and report the OOS accuracy.      ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1cc4e4",
   "metadata": {},
   "source": [
    "## Part II. CART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f518c43",
   "metadata": {},
   "source": [
    "Build a decision tree, visualize your tree and report the OOS accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Build a decision tree, visualize your tree and report the OOS accuracy.       ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad45122",
   "metadata": {},
   "source": [
    "## Part III. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c2776",
   "metadata": {},
   "source": [
    "Build a random forest, plot the variable importance and report the OOS accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Build a random forest, plot the variable importance and report the OOS accuracy.         ###\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a4466",
   "metadata": {},
   "source": [
    "## Part IV. Variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3453e",
   "metadata": {},
   "source": [
    "Does this dataset has some strong colinearility? Plot the heatmap of the variable correlations. Use this heatmap to explain the variable importance plot you got."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0bd4e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
